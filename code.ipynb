{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.exposure import match_histograms\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "import argparse\n",
        "import imutils\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.backend as k\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image, ImageOps"
      ],
      "metadata": {
        "id": "GMQIqcL8j0ek"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/CV/Dataset.zip -d Dataset\n",
        "!unzip /content/drive/MyDrive/CV/Patterns.zip -d Patterns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61V2tKmwmdOr",
        "outputId": "e12c57d3-0f2b-4876-9376-9f3a0774fef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/CV/Dataset.zip\n",
            "replace Dataset/1644359422.816138.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perspective(img, img_pattern):\n",
        "  gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  gray_img_pattern = cv2.cvtColor(img_pattern, cv2.COLOR_BGR2GRAY)\n",
        "  detect = cv2.ORB_create()\n",
        "  key_pt1,desc1 = detect.detectAndCompute(gray_img,None)\n",
        "  key_pt2,desc2 = detect.detectAndCompute(gray_img_pattern,None)\n",
        "  if type(desc1)!=type(None) and type(desc2)!=type(None) and desc1.shape[1] == desc2.shape[1]:\n",
        "    brute_force = cv2.BFMatcher(cv2.NORM_HAMMING,crossCheck=True)\n",
        "    no_of_matches = brute_force.match(desc1,desc2)\n",
        "    \n",
        "    matches = sorted(no_of_matches,key=lambda x:x.distance)  \n",
        "      \n",
        "    list_kp1 = np.float32([[int(key_pt1[mat.queryIdx].pt[0]), int(key_pt1[mat.queryIdx].pt[1])] for mat in matches]) \n",
        "    list_kp2 = np.float32([[int(key_pt2[mat.trainIdx].pt[0]), int(key_pt2[mat.trainIdx].pt[1])] for mat in matches])\n",
        "\n",
        "    if len(list_kp1) >= 4:\n",
        "      h, mask = cv2.findHomography(list_kp1, list_kp2, cv2.RANSAC, 5.0)\n",
        "      perspective_img = cv2.warpPerspective(img, h, img.shape[:2])\n",
        "      return perspective_img, h,1\n",
        "    else:\n",
        "      print(\"FAILED\")\n",
        "      return img, 0,0\n",
        "  else:\n",
        "      print(\"FAILED\")\n",
        "      return img, 0,0"
      ],
      "metadata": {
        "id": "Cp_CMkdRwwEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask(im, json_file):\n",
        "    mask = np.zeros(shape=(im.shape[0], im.shape[1]), dtype=np.float32)\n",
        "    for shape in json_file['shapes']:\n",
        "        points = np.array(shape['points'], dtype=np.int32)\n",
        "        cv2.fillPoly(mask, [points], 255)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "eBFdnt_DKAV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/Dataset/*\")\n",
        "idx=0\n",
        "for idx in range(len(files)) :\n",
        "  file = files[idx]\n",
        "  if(file.endswith('.json')):\n",
        "    continue\n",
        "  f = open(file[:-3]+\"json\", encoding=\"utf8\")\n",
        "  json_file = json.load(f)\n",
        "  f.close()\n",
        "  img1 = cv2.imread(file)\n",
        "  mask_img = get_mask(img1,json_file)\n",
        "  mask_img = mask_img[75:-75,75:-75] \n",
        "  img1 = img1[75:-75,75:-75] \n",
        "  \n",
        "  img2 = cv2.imread('/content/Patterns/' + json_file['pattern'])      \n",
        "  img2 = cv2.resize(img2, img1.shape[:2])\n",
        "  matched_img, t,r = perspective(img2, img1)\n",
        "  if(not r):\n",
        "    continue\n",
        "  url = f\"/content/drive/MyDrive/CV/Lastxxxx/img{idx}\"\n",
        "  cv2.imwrite(url+file[-4:], img1)\n",
        "  cv2.imwrite(url+\"_mask\"+file[-4:], mask_img)\n",
        "  cv2.imwrite(url+json_file['pattern'][-4:], matched_img)\n",
        "  "
      ],
      "metadata": {
        "id": "5hMlmRh1ysap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Siamese Model V1"
      ],
      "metadata": {
        "id": "m8H3xExNtXRQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9yDyUQ3PjMKY"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    inputs = layers.Input((16, 16, 1))\n",
        "    x =  layers.Conv2D(96, (11, 11), padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    pooledOutput = layers.GlobalAveragePooling2D()(x)\n",
        "    pooledOutput = layers.Dense(1024)(pooledOutput)\n",
        "    outputs = layers.Dense(128)(pooledOutput)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = create_model()\n",
        "imgA = layers.Input(shape=(16, 16, 1))\n",
        "imgB = layers.Input(shape=(16, 16, 1))\n",
        "featA = feature_extractor(imgA)\n",
        "featB = feature_extractor(imgB)"
      ],
      "metadata": {
        "id": "h6LNj3DWnYU5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vectors):\n",
        "    (featA, featB) = vectors\n",
        "    sum_squared = k.sum(k.square(featA - featB), axis=1, keepdims=True)\n",
        "    return k.sqrt(k.maximum(sum_squared, k.epsilon()))\n",
        "\n",
        "distance = layers.Lambda(euclidean_distance)([featA, featB])\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(distance)\n",
        "model =  keras.Model(inputs=[imgA, imgB], outputs=outputs)"
      ],
      "metadata": {
        "id": "2I1ljN9BoEpS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "UhtvA6-soR0B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window(image, stepSize, windowSize):\n",
        "\tfor y in range(0, image.shape[0], stepSize):\n",
        "\t\tfor x in range(0, image.shape[1], stepSize):\n",
        "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
      ],
      "metadata": {
        "id": "a_OpdbOQQejR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_image(image,points):\n",
        "    x,y,xw,yh = points\n",
        "    return image[y:yh, x:xw]"
      ],
      "metadata": {
        "id": "2w8VBgHLSonr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/CV/Last/*\")\n",
        "pair_images = []\n",
        "pair_labels = []\n",
        "(winW, winH) = (16,16)\n",
        "for idx in range(len(files)) :\n",
        "  file = files[idx]\n",
        "  if(file.endswith('.tif') or file.__contains__('mask')):\n",
        "    continue\n",
        "  img = cv2.imread(file,0)\n",
        "  pattern_img = cv2.imread(file[:-4]+\".tif\",0)\n",
        "  mask_img = cv2.imread(file[:-4]+\"_mask\"+file[-4:],0)\n",
        "\n",
        "  for (x, y, window) in sliding_window(img, stepSize=16, windowSize=(winW, winH)):\n",
        "      if (window.shape[0] != winH or window.shape[1] != winW):\n",
        "        continue\n",
        "      box = [x,y,x+winW,y+winH]\n",
        "      box_img = crop_image(img,box)\n",
        "      box_pattern_img = crop_image(pattern_img,box)\n",
        "      box_mask_img = crop_image(mask_img,box)\n",
        "      pair_images.append((box_img,box_pattern_img))\n",
        "      count = np.count_nonzero(box_mask_img)\n",
        "      if(count>100):\n",
        "        pair_labels.append(1)\n",
        "      else:\n",
        "        pair_labels.append(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "lWcDEwM0Qnrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet import preprocess_input\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, data, batch_size=32, dim=(16, 16), n_channels=1, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.files = data\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_channels = n_channels\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.files) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Initialization\n",
        "        pair_images = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        pair_labels = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ind in enumerate(indexes):\n",
        "              file = files[ind]\n",
        "              if(file.endswith('.tif') or file.__contains__('mask')):\n",
        "                continue\n",
        "              img = cv2.imread(file,0)\n",
        "              pattern_img = cv2.imread(file[:-4]+\".tif\",0)\n",
        "              mask_img = cv2.imread(file[:-4]+\"_mask\"+file[-4:],0)\n",
        "              (winW, winH) = self.dim\n",
        "              for (x, y, window) in sliding_window(img, stepSize=16, windowSize=(winW, winH)):\n",
        "                  if (window.shape[0] != winH or window.shape[1] != winW):\n",
        "                    continue\n",
        "                  box = [x,y,x+winW,y+winH]\n",
        "                  box_img = crop_image(img,box)\n",
        "                  box_pattern_img = crop_image(pattern_img,box)\n",
        "                  box_mask_img = crop_image(mask_img,box)\n",
        "                  pair_images[i]=(box_img,box_pattern_img)\n",
        "                  count = np.count_nonzero(box_mask_img)\n",
        "                  if(count>100):\n",
        "                    pair_labels[i]=1\n",
        "                  else:\n",
        "                    pair_labels[i]=0\n",
        "        return \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.files))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n"
      ],
      "metadata": {
        "id": "UIqCdwl4hwF-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/CV/Last/*\")\n",
        "train_generator = DataGenerator(files)\n",
        "valid_generator = DataGenerator(files, shuffle=False)\n",
        "X, y = train_generator.__getitem__(1)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "BBoplYcF9r3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,validation_data=valid_generator,bacepochs=50,batch_size=4)"
      ],
      "metadata": {
        "id": "ldG2oHVu9s9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Siamese(U-NET) Model V2"
      ],
      "metadata": {
        "id": "pWmIT8WWnjw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model = get_model((256,256), 1)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rubckzM89exe",
        "outputId": "62cbf30d-a731-4e2f-b621-e5d52df68548"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 128, 32  896         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 128, 128, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 128, 128, 32  0           ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d (SeparableCon  (None, 128, 128, 64  2400       ['activation_1[0][0]']           \n",
            " v2D)                           )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d[0][0]']       \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (SeparableC  (None, 128, 128, 64  4736       ['activation_2[0][0]']           \n",
            " onv2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['separable_conv2d_1[0][0]']     \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 64, 64)   2112        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 64, 64, 64)   0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 64, 64, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " separable_conv2d_2 (SeparableC  (None, 64, 64, 128)  8896       ['activation_3[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 128)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_3 (SeparableC  (None, 64, 64, 128)  17664      ['activation_4[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 128)  512        ['separable_conv2d_3[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 128)  8320        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 128)  0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 128)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " separable_conv2d_4 (SeparableC  (None, 32, 32, 256)  34176      ['activation_5[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_4[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_5 (SeparableC  (None, 32, 32, 256)  68096      ['activation_6[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 256)  1024       ['separable_conv2d_5[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 16, 16, 256)  33024       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 256)  0           ['max_pooling2d_2[0][0]',        \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 16, 16, 256)  590080     ['activation_7[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  590080     ['activation_8[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0          ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 256)  0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 256)  65792       ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 32, 32, 256)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 256)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  295040     ['activation_9[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_transpose_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 32, 32, 128)  147584     ['activation_10[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 128)  512        ['conv2d_transpose_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0          ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0          ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 128)  32896       ['up_sampling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64, 64, 128)  0           ['up_sampling2d_2[0][0]',        \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64, 64, 128)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 64, 64, 64)  73792       ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 64, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 64)  36928       ['activation_12[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 64)  256         ['conv2d_transpose_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 12  0          ['add_4[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 64  0          ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 64  8256        ['up_sampling2d_5[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 128, 128, 64  0           ['up_sampling2d_4[0][0]',        \n",
            "                                )                                 'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 64  0           ['add_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 32  18464      ['activation_13[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_6[0][0]']     \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 32  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 128, 128, 32  9248       ['activation_14[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 32  128        ['conv2d_transpose_7[0][0]']     \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 64  0          ['add_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 32  0          ['batch_normalization_14[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 256, 256, 32  2080        ['up_sampling2d_7[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 256, 256, 32  0           ['up_sampling2d_6[0][0]',        \n",
            "                                )                                 'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 256, 256, 1)  289         ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,058,401\n",
            "Trainable params: 2,054,625\n",
            "Non-trainable params: 3,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_network = get_model((256,256), 1)\n",
        "# Provided two tensors t1 and t2\n",
        "# Euclidean distance = sqrt(sum(square(t1-t2)))\n",
        "def euclidean_distance(vects):\n",
        "    \"\"\"Find the Euclidean distance between two vectors.\n",
        "\n",
        "    Arguments:\n",
        "        vects: List containing two tensors of same length.\n",
        "\n",
        "    Returns:\n",
        "        Tensor containing euclidean distance\n",
        "        (as floating point value) between vectors.\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = vects\n",
        "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
        "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
        "\n",
        "\n",
        "input_1 = layers.Input((256, 256, 3))\n",
        "input_2 = layers.Input((256, 256, 3))\n",
        "\n",
        "# As mentioned above, Siamese Network share weights between\n",
        "# tower networks (sister networks). To allow this, we will use\n",
        "# same embedding network for both tower networks.\n",
        "tower_1 = embedding_network(input_1)\n",
        "tower_2 = embedding_network(input_2)\n",
        "\n",
        "# merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
        "merge_layer = layers.Concatenate()([tower_1, tower_2])\n",
        "# subtracted = keras.layers.Subtract()([tower_1, tower_2])\n",
        "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
        "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
        "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
      ],
      "metadata": {
        "id": "4gMtpM4MvvJL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(margin=1):\n",
        "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
        "\n",
        "    Arguments:\n",
        "        margin: Integer, defines the baseline for distance for which pairs\n",
        "                should be classified as dissimilar. - (default is 1).\n",
        "\n",
        "    Returns:\n",
        "        'constrastive_loss' function with data ('margin') attached.\n",
        "    \"\"\"\n",
        "\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        \"\"\"Calculates the constrastive loss.\n",
        "\n",
        "        Arguments:\n",
        "            y_true: List of labels, each label is of type float32.\n",
        "            y_pred: List of predictions of same length as of y_true,\n",
        "                    each label is of type float32.\n",
        "\n",
        "        Returns:\n",
        "            A tensor containing constrastive loss as floating point value.\n",
        "        \"\"\"\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive_loss"
      ],
      "metadata": {
        "id": "5-3ir2Chxo2M"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese.compile(loss=loss(margin=1), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
        "siamese.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdqTrZ2Qt8Bq",
        "outputId": "26527bf2-5646-43b1-a203-e892a7ec5731"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " model_2 (Functional)           (None, 256, 256, 1)  2058401     ['input_6[0][0]',                \n",
            "                                                                  'input_7[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256, 256, 2)  0           ['model_2[0][0]',                \n",
            "                                                                  'model_2[1][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 256, 256, 2)  8          ['concatenate[0][0]']            \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256, 256, 1)  3           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,058,412\n",
            "Trainable params: 2,054,632\n",
            "Non-trainable params: 3,780\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/CV/Last/*\")\n",
        "x_train = []\n",
        "y_train = []\n",
        "(winW, winH) = (256,256)\n",
        "for idx in range(len(files)) :\n",
        "  file = files[idx]\n",
        "  if(file.endswith('.tif') or file.__contains__('mask')):\n",
        "    continue\n",
        "  img =cv2.resize(cv2.imread(file),(winW, winH))\n",
        "  pattern_img = cv2.resize(cv2.imread(file[:-4]+\".tif\"),(winW, winH))\n",
        "  mask_img = cv2.resize(cv2.imread(file[:-4]+\"_mask\"+file[-4:],0),(winW, winH))\n",
        "  x_train.append((img,pattern_img))\n",
        "  y_train.append(mask_img)"
      ],
      "metadata": {
        "id": "S3k7PAR1ltYH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train  = np.array(x_train),np.array(y_train).astype(\"float32\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "2OS5ovGHt95b"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzXA-_aXx5e9",
        "outputId": "6c57a34c-742b-4327-cf81-ee114636764e"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model, doing validation at the end of each epoch.\n",
        "history = siamese.fit([x_train[:, 0], x_train[:, 1]],y_train,batch_size=4,epochs=5, validation_data=([x_test[:, 0], x_test[:, 1]], y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxNqIX3E-gSQ",
        "outputId": "27eb1f1b-a7a7-49ec-fe8d-cd3059436506"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "61/61 [==============================] - 350s 6s/step - loss: 0.2457 - accuracy: 0.9986 - val_loss: 0.2414 - val_accuracy: 0.9983\n",
            "Epoch 2/5\n",
            "61/61 [==============================] - 318s 5s/step - loss: 0.2392 - accuracy: 0.9986 - val_loss: 0.2393 - val_accuracy: 0.9983\n",
            "Epoch 3/5\n",
            "61/61 [==============================] - 318s 5s/step - loss: 0.2333 - accuracy: 0.9986 - val_loss: 0.2373 - val_accuracy: 0.9983\n",
            "Epoch 4/5\n",
            "61/61 [==============================] - 319s 5s/step - loss: 0.2282 - accuracy: 0.9986 - val_loss: 0.2356 - val_accuracy: 0.9983\n",
            "Epoch 5/5\n",
            "61/61 [==============================] - 325s 5s/step - loss: 0.2242 - accuracy: 0.9986 - val_loss: 0.2346 - val_accuracy: 0.9983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = siamese.fit([x_train[:, 0], x_train[:, 1]],y_train,batch_size=4,epochs=5, validation_data=([x_test[:, 0], x_test[:, 1]], y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elC0qA_mmgYW",
        "outputId": "15c6013d-0e6d-43d8-9402-944345c74107"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "49/49 [==============================] - 176s 3s/step - loss: 0.2450 - accuracy: 0.9987 - val_loss: 0.2173 - val_accuracy: 0.9986\n",
            "Epoch 2/5\n",
            "49/49 [==============================] - 163s 3s/step - loss: 0.2379 - accuracy: 0.9987 - val_loss: 0.2133 - val_accuracy: 0.9986\n",
            "Epoch 3/5\n",
            "49/49 [==============================] - 164s 3s/step - loss: 0.2317 - accuracy: 0.9987 - val_loss: 0.2112 - val_accuracy: 0.9986\n",
            "Epoch 4/5\n",
            "49/49 [==============================] - 160s 3s/step - loss: 0.2262 - accuracy: 0.9987 - val_loss: 0.2102 - val_accuracy: 0.9986\n",
            "Epoch 5/5\n",
            "49/49 [==============================] - 164s 3s/step - loss: 0.2216 - accuracy: 0.9987 - val_loss: 0.2098 - val_accuracy: 0.9986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_metric(history, metric, title, has_valid=True):\n",
        "    \"\"\"Plots the given 'metric' from 'history'.\n",
        "\n",
        "    Arguments:\n",
        "        history: history attribute of History object returned from Model.fit.\n",
        "        metric: Metric to plot, a string value present as key in 'history'.\n",
        "        title: A string to be used as title of plot.\n",
        "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    plt.plot(history[metric])\n",
        "    if has_valid:\n",
        "        plt.plot(history[\"val_\" + metric])\n",
        "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot the accuracy\n",
        "plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
        "\n",
        "# Plot the constrastive loss\n",
        "plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "5r78Sv5z9VjD",
        "outputId": "a50317f7-adbd-449e-8980-bcd9727c8772"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5xWdZ338dfbEUUUEYFulSEhxWLA4YcTupmBEYayiaAGJq7oIpvhara0YXmvLcWt7sNl3XZdywpvLREN06jFwBRCbn/EoEggikh6M2CJqGAK6sBn/zjfgYthgAuaMxfMvJ+Px/XgXN8f53zO4XFdn/l+z7nOUURgZmaWp4NKHYCZmTV/TjZmZpY7JxszM8udk42ZmeXOycbMzHLnZGNmZrlzsjFrRJK6SgpJBxfRdoykBU0Rl1mpOdlYiyXpFUkfSOpYr/zZlDC6liYys+bHycZauj8AF9W9kXQy0KZ04ewfihmZme0NJxtr6X4C/E3B+0uBuwsbSGon6W5J6yS9Kul6SQelujJJt0h6Q9IqYGgDfX8s6TVJayR9V1JZMYFJ+pmkP0raIGm+pJ4FdYdJ+tcUzwZJCyQdluo+LekJSW9LWi1pTCqfJ2lswTp2mMZLo7nxkl4CXkpl/57WsVHSIklnFLQvk/RNSS9LeifVd5F0m6R/rbcvMyVdW8x+W/PkZGMt3VPAkZJ6pCQwCvhpvTb/AbQDPgYMIEtOl6W6K4C/BvoCVcAF9fr+X6AWODG1OQsYS3EeBroDHwGeAe4pqLsFOAX4FHA08I/AVknHp37/AXQC+gCLi9wewHnAqUBFer8wreNoYBrwM0mtU93XyEaF5wBHApcD7wF3ARcVJOSOwOdSf2upIsIvv1rkC3iF7EvweuBGYAjwCHAwEEBXoAz4AKgo6Pd3wLy0/Bjw5YK6s1Lfg4H/BbwPHFZQfxEwNy2PARYUGetRab3tyP5I3AT0bqDddcCDu1jHPGBswfsdtp/W/9k9xPFW3XaBF4Fhu2i3HBiclq8CZpX6/9uv0r48L2uWTaXNB7pRbwoN6Ai0Al4tKHsV6JyWjwNW16urc3zq+5qkurKD6rVvUBplTQYuJBuhbC2I51CgNfByA1277KK8WDvEJmkC8Ldk+xlkI5i6Cyp2t627gNFkyXs08O9/QUzWDHgazVq8iHiV7EKBc4Cf16t+A/iQLHHU+SiwJi2/RvalW1hXZzXZyKZjRByVXkdGRE/27EvAMLKRVzuyURaAUkybgRMa6Ld6F+UA77LjxQ/HNNBm223g0/mZfwS+CLSPiKOADSmGPW3rp8AwSb2BHsBDu2hnLYSTjVnmb8mmkN4tLIyILcD9wGRJbdM5ka+x/bzO/cDVksoltQcmFvR9DZgD/KukIyUdJOkESQOKiKctWaJaT5Yg/k/BercCU4Epko5LJ+r/StKhZOd1Pifpi5IOltRBUp/UdTEwQlIbSSemfd5TDLXAOuBgSf9ENrKp8yPgO5K6K1MpqUOKsYbsfM9PgAciYlMR+2zNmJONGRARL0dE9S6q/55sVLAKWEB2ontqqvshMBt4juwkfv2R0d8AhwDPk53vmAEcW0RId5NNya1JfZ+qVz8B+D3ZF/qbwM3AQRHx/8lGaP+QyhcDvVOffyM7//Qnsmmue9i92cCvgRUpls3sOM02hSzZzgE2Aj8GDiuovws4mSzhWAunCD88zcwan6TPkI0Ajw9/0bR4HtmYWaOT1Aq4BviRE42Bk42ZNTJJPYC3yaYLby1xOLaf8DSamZnlziMbMzPLnX/U2YCOHTtG165dSx2GmdkBZdGiRW9ERKeG6pxsGtC1a1eqq3d1FayZmTVE0qu7qvM0mpmZ5c7JxszMcudkY2ZmufM5myJ9+OGH1NTUsHnz5lKH0my0bt2a8vJyWrVqVepQzCxnTjZFqqmpoW3btnTt2pWC28XbPooI1q9fT01NDd26dSt1OGaWM0+jFWnz5s106NDBiaaRSKJDhw4eKZq1EE42e8GJpnH5eJq1HJ5Ga2Rr397Epg+3lDqMA8a6d97n2z94stRhmFlScdyR3PCFYp7vt3c8sjmAbNzwNj+d+sO97ve3F53Pxg1v5xCRmVlxPLJpZMcdddieG+2jV959g5/95Mfc8I1rdyivra3l4IN3/V857zezc4vpL/XBG4dy39/12XNDMzugOdkcQCZOnMjLL79Mnz59aNWqFa1bt6Z9+/a88MILrFixgvPOO4/Vq1ezefNmrrnmGsaNGwdsv/3On//8Z84++2w+/elP88QTT9C5c2d+8YtfcNhh+SVIMzNwstkn//zLZTy/dmOjrrOYedKbbrqJpUuXsnjxYubNm8fQoUNZunTptkuHp06dytFHH82mTZv45Cc/yfnnn0+HDh12WMdLL73Evffeyw9/+EO++MUv8sADDzB69OhG3Rczs/qcbA5g/fv33+E3Kt/73vd48MEHAVi9ejUvvfTSTsmmW7du9OmTTVudcsopvPLKK00Wr5m1XE42+yCPKzX2xeGHH75ted68efzmN7/hySefpE2bNgwcOLDB37Aceuih25bLysrYtGlTk8RqZi2br0Y7gLRt25Z33nmnwboNGzbQvn172rRpwwsvvMBTTz3VxNGZme1arslG0hBJL0paKWliA/XHS3pU0hJJ8ySVF9TdLGlpeo0sKB8k6RlJiyUtkHRiQd0XJT0vaZmkaQXll0p6Kb0uzXOf89ShQwdOP/10evXqxde//vUd6oYMGUJtbS09evRg4sSJnHbaaSWK0sxsZ4qIfFYslQErgMFADbAQuCgini9o8zPgVxFxl6TPApdFxCWShgJfBc4GDgXmAYMiYqOkFcCwiFgu6StA/4gYI6k7cD/w2Yh4S9JHIuJ1SUcD1UAVEMAi4JSIeGtXsVdVVUX9h6ctX76cHj16NMqxse18XM2aD0mLIqKqobo8Rzb9gZURsSoiPgCmA8PqtakAHkvLcwvqK4D5EVEbEe8CS4AhqS6AI9NyO2BtWr4CuK0uiUTE66n888AjEfFmqnukYF1mZtYE8kw2nYHVBe9rUlmh54ARaXk40FZSh1Q+RFIbSR2BM4Euqd1YYJakGuAS4KZUfhJwkqT/J+kpSXUJpZg4kDROUrWk6nXr1u3D7pqZ2a6U+gKBCcAASc8CA4A1wJaImAPMAp4A7gWeBOpuOHYtcE5ElAN3AlNS+cFAd2AgcBHwQ0lHFRtIRNwREVURUdWpU6e/eMfMzGy7PJPNGraPRgDKU9k2EbE2IkZERF/gW6ns7fTv5IjoExGDAQErJHUCekfE02kV9wGfSss1wMyI+DAi/kB2vqh7MXGYmVm+8kw2C4HukrpJOgQYBcwsbCCpo6S6GK4DpqbysjSdhqRKoBKYA7wFtJN0UuozGFielh8iG9WQpt5OAlYBs4GzJLWX1B44K5WZmVkTye1HnRFRK+kqsi/2MmBqRCyTNAmojoiZZMnhRkkBzAfGp+6tgMfT8042AqMjohZA0hXAA5K2kiWfy1OfuqTyPNmU29cjYn3q8x2y5AcwKSLezGu/zcxsZ7mes4mIWRFxUkScEBGTU9k/pURDRMyIiO6pzdiIeD+Vb46IivQ6LSIWF6zzwYg4OSJ6R8TAiFiVyiMivpb6nBwR0wv6TI2IE9Przjz3eX9yxBFHALB27VouuOCCBtsMHDiQ+pd513frrbfy3nvvbXt/zjnn8PbbfmSBmRWv1BcIWBM47rjjmDFjxj73r59sZs2axVFHFX3thZmZk82BZOLEidx2223b3n/729/mu9/9LoMGDaJfv36cfPLJ/OIXv9ip3yuvvEKvXr0A2LRpE6NGjaJHjx4MHz58h3ujXXnllVRVVdGzZ09uuOEGILu559q1aznzzDM588wzgeyRBW+88QYAU6ZMoVevXvTq1Ytbb7112/Z69OjBFVdcQc+ePTnrrLN8DzazFs434twXD0+EP/6+cdd5zMlw9k27bTJy5Ei++tWvMn58dmrr/vvvZ/bs2Vx99dUceeSRvPHGG5x22mmce+65pPNdO7n99ttp06YNy5cvZ8mSJfTr129b3eTJkzn66KPZsmULgwYNYsmSJVx99dVMmTKFuXPn0rFjxx3WtWjRIu68806efvppIoJTTz2VAQMG0L59ez/KwMx24JHNAaRv3768/vrrrF27lueee4727dtzzDHH8M1vfpPKyko+97nPsWbNGv70pz/tch3z58/f9qVfWVlJZWXltrr777+ffv360bdvX5YtW8bzzz+/q9UAsGDBAoYPH87hhx/OEUccwYgRI3j88ccBP8rAzHbkkc2+2MMIJE8XXnghM2bM4I9//CMjR47knnvuYd26dSxatIhWrVrRtWvXBh8tsCd/+MMfuOWWW1i4cCHt27dnzJgx+7SeOn6UgZkV8sjmADNy5EimT5/OjBkzuPDCC9mwYQMf+chHaNWqFXPnzuXVV1/dbf/PfOYzTJuW3RB76dKlLFmyBICNGzdy+OGH065dO/70pz/x8MMPb+uzq0cbnHHGGTz00EO89957vPvuuzz44IOcccYZjbi3ZtZceGRzgOnZsyfvvPMOnTt35thjj+Xiiy/mC1/4AieffDJVVVV84hOf2G3/K6+8kssuu4wePXrQo0cPTjnlFAB69+5N3759+cQnPkGXLl04/fTTt/UZN24cQ4YM4bjjjmPu3Lnbyvv168eYMWPo378/AGPHjqVv376eMjOzneT2iIEDmR8x0HR8XM2aj1I9YsDMzAxwsjEzsybgZLMXPOXYuHw8zVoOJ5sitW7dmvXr1/sLspFEBOvXr6d169alDsXMmoCvRitSeXk5NTU1+Cmejad169aUl5eXOgwzawJONkVq1aoV3bp1K3UYZmYHJE+jmZlZ7pxszMwsd042ZmaWOycbMzPLnZONmZnlzsnGzMxy52RjZma5yzXZSBoi6UVJKyVNbKD+eEmPSloiaZ6k8oK6myUtTa+RBeWDJD0jabGkBZJOTOVjJK1L5YsljS3os6WgfGae+2xmZjvL7UedksqA24DBQA2wUNLMiCh81vAtwN0RcZekzwI3ApdIGgr0A/oAhwLzJD0cERuB24FhEbFc0leA64ExaX33RcRVDYSzKSL65LCbZmZWhDxHNv2BlRGxKiI+AKYDw+q1qQAeS8tzC+orgPkRURsR7wJLgCGpLoAj03I7YG1O8ZuZWSPJM9l0BlYXvK9JZYWeA0ak5eFAW0kdUvkQSW0kdQTOBLqkdmOBWZJqgEuAmwrWd36akpshqUtBeWtJ1ZKeknReQ8FKGpfaVPv+Z2ZmjavUFwhMAAZIehYYAKwBtkTEHGAW8ARwL/AksCX1uRY4JyLKgTuBKan8l0DXiKgEHgHuKtjO8enpcV8CbpV0Qv1AIuKOiKiKiKpOnTo19n6ambVoeSabNWwfjQCUp7JtImJtRIyIiL7At1LZ2+nfyRHRJyIGAwJWSOoE9I6Ip9Mq7gM+ldqvj4j3U/mPgFMKtrMm/bsKmAf0bcwdNTOz3csz2SwEukvqJukQYBSww5VgkjpKqovhOmBqKi9L02lIqgQqgTnAW0A7SSelPoOB5andsQWrPregvL2kQ+u2B5wOFF6kYGZmOcvtarSIqJV0FTAbKAOmRsQySZOA6oiYCQwEbpQUwHxgfOreCnhcEsBGYHRE1AJIugJ4QNJWsuRzeepztaRzgVrgTbZfodYD+EFqfxBwU70r4szMLGfykyd3VlVVFdXV1aUOw8zsgCJpUTo/vpNSXyBgZmYtgJONmZnlzsnGzMxy52RjZma5c7IxM7PcOdmYmVnunGzMzCx3TjZmZpY7JxszM8udk42ZmeXOycbMzHLnZGNmZrlzsjEzs9w52ZiZWe6cbMzMLHdONmZmljsnGzMzy52TjZmZ5c7JxszMcudkY2Zmucs12UgaIulFSSslTWyg/nhJj0paImmepPKCupslLU2vkQXlgyQ9I2mxpAWSTkzlYyStS+WLJY0t6HOppJfS69I899nMzHaWW7KRVAbcBpwNVAAXSaqo1+wW4O6IqAQmATemvkOBfkAf4FRggqQjU5/bgYsjog8wDbi+YH33RUSf9PpRWtfRwA1pPf2BGyS1b/QdNjOzXcpzZNMfWBkRqyLiA2A6MKxemwrgsbQ8t6C+ApgfEbUR8S6wBBiS6gKoSzztgLV7iOPzwCMR8WZEvAU8UrAuMzNrAnkmm87A6oL3Nams0HPAiLQ8HGgrqUMqHyKpjaSOwJlAl9RuLDBLUg1wCXBTwfrOT1NyMyTVtS8mDjMzy1GpLxCYAAyQ9CwwAFgDbImIOcAs4AngXuBJYEvqcy1wTkSUA3cCU1L5L4GuaUruEeCuvQlE0jhJ1ZKq161b9xfulpmZFcoz2axh+2gEoDyVbRMRayNiRET0Bb6Vyt5O/05O514GAwJWSOoE9I6Ip9Mq7gM+ldqvj4j3U/mPgFOKjSP1vyMiqiKiqlOnTvu802ZmtrM8k81CoLukbpIOAUYBMwsbSOooqS6G64CpqbwsTachqRKoBOYAbwHtJJ2U+gwGlqd2xxas+ty6cmA2cJak9unCgLNSmZmZNZGD81pxRNRKuorsi70MmBoRyyRNAqojYiYwELhRUgDzgfGpeyvgcUkAG4HREVELIOkK4AFJW8mSz+Wpz9WSzgVqgTeBMSmONyV9hyz5AUyKiDfz2m8zM9uZIqLUMex3qqqqorq6utRhmJkdUCQtioiqhupKfYGAmZm1AE42ZmaWOycbMzPLnZONmZnlrqhkI+nnkoYWXKZsZmZWtGKTx38BXwJeknSTpI/nGJOZmTUzRSWbiPhNRFxMdifmV4DfSHpC0mWSWuUZoJmZHfiKnhZLv+gfQ3YjzGeBfydLPo/kEpmZmTUbRd1BQNKDwMeBnwBfiIjXUtV9kvzrRzMz261ib1fzvYiY21DFrn4tamZmVqfYabQKSUfVvUk3tfxKTjGZmVkzU2yyuaLu1v8A6YmXV+QTkpmZNTfFJpsypVswQ/YIAOCQfEIyM7PmpthzNr8muxjgB+n936UyMzOzPSo22XyDLMFcmd4/QvY0TDMzsz0qKtlExFbg9vQyMzPbK8X+zqY7cCNQAbSuK4+Ij+UUl5mZNSPFXiBwJ9mophY4E7gb+GleQZmZWfNSbLI5LCIeJXuM9KsR8W1gaH5hmZlZc1LsBQLvp8cLvCTpKmANcER+YZmZWXNS7MjmGqANcDVwCjAauDSvoMzMrHnZY7JJP+AcGRF/joiaiLgsIs6PiKeK6DtE0ouSVkqa2ED98ZIelbRE0jxJ5QV1N0taml4jC8oHSXpG0mJJCySdWG+d50sKSVXpfVdJm1L7xZK+v6e4zcysce0x2UTEFuDTe7vilKRuA84mu4rtIkkV9ZrdAtwdEZXAJLIr3pA0lOzxBX2AU4EJko5MfW4HLo6IPsA04PqCbbYlG4U9XW87L0dEn/T68t7ui5mZ/WWKnUZ7VtJMSZdIGlH32kOf/sDKiFgVER8A04Fh9dpUAI+l5bkF9RXA/IiojYh3gSXAkFQXQF3iaQesLVjfd4Cbgc1F7peZmTWBYpNNa2A98FngC+n113vo0xlYXfC+JpUVeg6oS1rDgbbpIW3PAUMktZHUkexy6y6p3VhglqQa4BLgJgBJ/YAuEfHfDcTSTdKzkn4r6YyGgpU0TlK1pOp169btYdfMzGxvFHsHgcty2v4E4D8ljQHmk13ltiUi5kj6JPAEsA54EtiS+lwLnBMRT0v6OjBF0jhgCtmTROt7DfhoRKyXdArwkKSeEbGxsFFE3AHcAVBVVRWNvJ9mZi1asXcQuJNs+moHEXH5brqtYftoBKA8lRX2X0sa2Ug6Aji/7lEGETEZmJzqpgErJHUCekdE3TmZ+8huCNoW6AXMSzenPgaYKenciKgG3k/rXCTpZeAkwE8YNTNrIsX+zuZXBcutyaa81u6ibZ2FQHdJ3ciSzCjgS4UN0hTZm+nea9cBU1N5GXBUGo1UApXAnNStnaSTImIFMBhYHhEbgI4F650HTIiI6pSg3oyILZI+BnQHVhW532Zm1giKnUZ7oPC9pHuBBXvoU5t+ADobKAOmRsQySZOA6oiYCQwEbpQUZNNo41P3VsDjaZSyERgdEbVp21cAD0jaCrwF7G50BfAZYJKkD4GtwJcj4s1i9tvMzBqHIvb+9ISkjwP/HREn7rHxAaiqqiqqqz3LZma2NyQtioiqhuqKPWfzDjues/kj2TNuzMzM9qjYabS2eQdiZmbNV1G/s5E0XFK7gvdHSTovv7DMzKw5KfZHnTekK74ASJcn35BPSGZm1twUm2waalfsZdNmZtbCFZtsqiVNkXRCek0BFuUZmJmZNR/FJpu/Bz4g+8X+dLIbXY7fbQ8zM7Ok2KvR3gV2eh6NmZlZMYq9Gu0RSUcVvG8vaXZ+YZmZWXNS7DRax7obZAJExFvAR/IJyczMmptik81WSR+teyOpKw3cBdrMzKwhxV6+/C1ggaTfAgLOAMblFpWZmTUrxV4g8GtJVWQJ5lngIWBTnoGZmVnzUeyNOMcC15A9AG0xcBrZ0zM/m19oZmbWXBR7zuYa4JPAqxFxJtAXeHv3XczMzDLFJpvNEbEZQNKhEfEC8PH8wjIzs+ak2AsEatLvbB4CHpH0FvBqfmGZmVlzUuwFAsPT4rclzQXaAb/OLSozM2tW9vrOzRHx2zwCMTOz5qvYczZmZmb7zMnGzMxyl2uykTRE0ouSVkra6a7Rko6X9KikJZLmSSovqLtZ0tL0GllQPkjSM5IWS1og6cR66zxfUqQfodaVXZdieFHS5/PaXzMza1huyUZSGXAbcDZQAVwkqaJes1uAuyOiEpgE3Jj6DgX6AX2AU4EJko5MfW4HLo6IPsA04PqCbbYl+03Q0wVlFcAooCcwBPivFJuZmTWRPEc2/YGVEbEqIj4ge+jasHptKoDH0vLcgvoKYH5E1KZn6SwhSxSQ3QC0LvG0A9YWrO87wM1kD3erMwyYHhHvR8QfgJUpNjMzayJ5JpvOwOqC9zWprNBzwIi0PBxoK6lDKh8iqY2kjsCZQJfUbiwwS1INcAlwE4CkfkCXiPjvfYgDSeMkVUuqXrdu3d7tqZmZ7VapLxCYAAyQ9CwwAFgDbImIOcAs4AngXrL7sG1Jfa4FzomIcuBOYIqkg4ApwD/sayARcUdEVEVEVadOnfZ5h8zMbGd7/TubvbCG7aMRyG7iuaawQUSsJY1sJB0BnF/3kLaImAxMTnXTgBWSOgG9I6LunMx9ZD8ubQv0AuZJAjgGmCnp3GLiMDOzfOU5slkIdJfUTdIhZCfpZxY2kNQxjUoArgOmpvKyNJ2GpEqgEpgDvAW0k3RS6jMYWB4RGyKiY0R0jYiuwFPAuRFRnbY5StKhkroB3YHf5bfbZmZWX24jm4iolXQVMBsoA6ZGxDJJk4DqiJgJDARulBTAfGB86t4KeDyNUjYCoyOiFkDSFcADkraSJZ/L9xDHMkn3A88DtcD4iNiyuz5mZta4FOGnO9dXVVUV1dXVpQ7DzOyAImlRRFQ1VFfqCwTMzKwFcLIxM7PcOdmYmVnunGzMzCx3TjZmZpY7JxszM8udk42ZmeXOycbMzHLnZGNmZrlzsjEzs9w52ZiZWe6cbMzMLHdONmZmljsnGzMzy52TjZmZ5c7JxszMcudkY2ZmuXOyMTOz3DnZmJlZ7pxszMwsd042ZmaWu1yTjaQhkl6UtFLSxAbqj5f0qKQlkuZJKi+ou1nS0vQaWVA+SNIzkhZLWiDpxFT+ZUm/LyivSOVdJW1K5YslfT/PfTYzs53llmwklQG3AWcDFcBFdQmgwC3A3RFRCUwCbkx9hwL9gD7AqcAESUemPrcDF0dEH2AacH0qnxYRJ6fyfwGmFGzn5Yjok15fbux9NTOz3ctzZNMfWBkRqyLiA2A6MKxemwrgsbQ8t6C+ApgfEbUR8S6wBBiS6gKoSzztgLUAEbGxYL2Hp3ZmZrYfyDPZdAZWF7yvSWWFngNGpOXhQFtJHVL5EEltJHUEzgS6pHZjgVmSaoBLgJvqViZpvKSXyUY2Vxdsp5ukZyX9VtIZDQUraZykaknV69at25f9NTOzXSj1BQITgAGSngUGAGuALRExB5gFPAHcCzwJbEl9rgXOiYhy4E4Kpssi4raIOAH4Btun114DPhoRfYGvAdMKpuQo6HtHRFRFRFWnTp1y2FUzs5Yrz2Szhu2jEYDyVLZNRKyNiBEpEXwrlb2d/p2czrEMBgSskNQJ6B0RT6dV3Ad8qoFtTwfOS+t5PyLWp+VFwMvASY20j2ZmVoQ8k81CoLukbpIOAUYBMwsbSOooqS6G64CpqbwsTachqRKoBOYAbwHtJNUli8HA8tSue8GqhwIvpfJO6WIFJH0M6A6sauR9NTOz3Tg4rxVHRK2kq4DZQBkwNSKWSZoEVEfETGAgcKOkAOYD41P3VsDjkgA2AqMjohZA0hXAA5K2kiWfy1OfqyR9DvgwlV+ayj8DTJL0IbAV+HJEvJnXfpuZ2c4U4Yu26quqqorq6upSh2FmdkCRtCgiqhqqK/UFAmZm1gI42ZiZWe6cbMzMLHdONmZmljsnGzMzy52TjZmZ5c7JxszMcudkY2ZmuXOyMTOz3DnZmJlZ7pxszMwsd042ZmaWOycbMzPLnZONmZnlzsnGzMxy52RjZma5c7IxM7PcOdmYmVnunGzMzCx3TjZmZpa7XJONpCGSXpS0UtLEBuqPl/SopCWS5kkqL6i7WdLS9BpZUD5I0jOSFktaIOnEVP5lSb8vKK8o6HNdiuFFSZ/Pc5/NzGxnuSUbSWXAbcDZQAVwUWECSG4B7o6ISmAScGPqOxToB/QBTgUmSDoy9bkduDgi+gDTgOtT+bSIODmV/wswJa2rAhgF9ASGAP+VYjMzsyaS58imP7AyIlZFxAfAdGBYvTYVwGNpeW5BfQUwPyJqI+JdYAlZogAIoC7xtAPWAkTExoL1Hp7akdY5PSLej4g/ACtTbGZm1kTyTDadgdUF72tSWaHngBFpeTjQVlKHVD5EUhtJHYEzgS6p3VhglqQa4BLgprqVSRov6WWykc3VexGHmZnlqNQXCEwABkh6FhgArAG2RH73dawAAAeBSURBVMQcYBbwBHAv8CSwJfW5FjgnIsqBO0nTZQARcVtEnAB8g+3Ta0WRNE5StaTqdevW/YW7ZWZmhfJMNmvYPhoBKE9l20TE2ogYERF9gW+lsrfTv5Mjok9EDAYErJDUCegdEU+nVdwHfKqBbU8Hzis2jrS9OyKiKiKqOnXqtJe7amZmu5NnslkIdJfUTdIhZCfpZxY2kNRRUl0M1wFTU3lZmk5DUiVQCcwB3gLaSTop9RkMLE/tuheseijwUlqeCYySdKikbkB34HeNuqdmZrZbB+e14oiolXQVMBsoA6ZGxDJJk4DqiJgJDARulBTAfGB86t4KeFwSwEZgdETUAki6AnhA0lay5HN56nOVpM8BH6byS1McyyTdDzwP1ALjI6JuSs7MzJqAImLPrVqYqqqqqK6uLnUYZmYHFEmLIqKqobpSXyBgZmYtgJONmZnlzsnGzMxyl9sFAi3WwxPhj78vdRRmZvvmmJPh7Jv23G4veWRjZma588imseXwF4GZ2YHOIxszM8udk42ZmeXOycbMzHLnZGNmZrlzsjEzs9w52ZiZWe6cbMzMLHdONmZmljs/YqABktYBr/4Fq+gIvNFI4TQmx7V3HNfecVx7pznGdXxENPioYyebHEiq3tUzHUrJce0dx7V3HNfeaWlxeRrNzMxy52RjZma5c7LJxx2lDmAXHNfecVx7x3HtnRYVl8/ZmJlZ7jyyMTOz3DnZmJlZ7pxs9pGkIZJelLRS0sQG6g+VdF+qf1pS1/0krjGS1klanF5jmyiuqZJel7R0F/WS9L0U9xJJ/faTuAZK2lBwvP6pieLqImmupOclLZN0TQNtmvyYFRlXkx8zSa0l/U7Scymuf26gTZN/JouMqySfybTtMknPSvpVA3WNe7wiwq+9fAFlwMvAx4BDgOeAinptvgJ8Py2PAu7bT+IaA/xnCY7ZZ4B+wNJd1J8DPAwIOA14ej+JayDwqxIcr2OBfmm5LbCigf/LJj9mRcbV5McsHYMj0nIr4GngtHptSvGZLCauknwm07a/Bkxr6P+rsY+XRzb7pj+wMiJWRcQHwHRgWL02w4C70vIMYJAk7QdxlUREzAfe3E2TYcDdkXkKOErSsftBXCUREa9FxDNp+R1gOdC5XrMmP2ZFxtXk0jH4c3rbKr3qX/3U5J/JIuMqCUnlwFDgR7to0qjHy8lm33QGVhe8r2HnD9y2NhFRC2wAOuwHcQGcn6ZdZkjqknNMxSo29lL4qzQN8rCknk298TR90Zfsr+JCJT1mu4kLSnDM0pTQYuB14JGI2OXxasLPZDFxQWk+k7cC/whs3UV9ox4vJ5uW55dA14ioBB5h+18u1rBnyO731Bv4D+Chpty4pCOAB4CvRsTGptz27uwhrpIcs4jYEhF9gHKgv6ReTbHdPSkirib/TEr6a+D1iFiU97bqONnsmzVA4V8f5amswTaSDgbaAetLHVdErI+I99PbHwGn5BxTsYo5pk0uIjbWTYNExCyglaSOTbFtSa3IvtDviYifN9CkJMdsT3GV8pilbb4NzAWG1KsqxWdyj3GV6DN5OnCupFfIpts/K+mn9do06vFystk3C4HukrpJOoTs5NnMem1mApem5QuAxyKdaStlXPXm9M8lm3PfH8wE/iZdYXUasCEiXit1UJKOqZunltSf7DOT+xdU2uaPgeURMWUXzZr8mBUTVymOmaROko5Ky4cBg4EX6jVr8s9kMXGV4jMZEddFRHlEdCX7nngsIkbXa9aox+vgfe3YkkVEraSrgNlkV4BNjYhlkiYB1RExk+wD+RNJK8lOQI/aT+K6WtK5QG2Ka0zecQFIupfsKqWOkmqAG8hOlhIR3wdmkV1dtRJ4D7hsP4nrAuBKSbXAJmBUE/zRANlfnpcAv0/z/QDfBD5aEFspjlkxcZXimB0L3CWpjCy53R8Rvyr1Z7LIuErymWxInsfLt6sxM7PceRrNzMxy52RjZma5c7IxM7PcOdmYmVnunGzMzCx3TjZmzYyyuy7vdBdfs1JysjEzs9w52ZiViKTR6VkniyX9IN2w8c+S/i09++RRSZ1S2z6Snko3a3xQUvtUfqKk36SbXj4j6YS0+iPSTR1fkHRPE9xx3Gy3nGzMSkBSD2AkcHq6SeMW4GLgcLJfcPcEfkt2RwOAu4FvpJs1/r6g/B7gtnTTy08Bdber6Qt8Fagge77R6bnvlNlu+HY1ZqUxiOyGiwvToOMwslvQbwXuS21+CvxcUjvgqIj4bSq/C/iZpLZA54h4ECAiNgOk9f0uImrS+8VAV2BB/rtl1jAnG7PSEHBXRFy3Q6H0v+u129f7Sb1fsLwFf9atxDyNZlYajwIXSPoIgKSjJR1P9pm8ILX5ErAgIjYAb0k6I5VfAvw2PSmzRtJ5aR2HSmrTpHthViT/tWNWAhHxvKTrgTmSDgI+BMYD75I9YOt6smm1kanLpcD3UzJZxfY7PF8C/CDdrfdD4MIm3A2zovmuz2b7EUl/jogjSh2HWWPzNJqZmeXOIxszM8udRzZmZpY7JxszM8udk42ZmeXOycbMzHLnZGNmZrn7HzZ5l0tEFRp3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-Net model\n"
      ],
      "metadata": {
        "id": "F4Grf3iyP4MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"/content/drive/MyDrive/CV/Last/*\")\n",
        "x_test= []\n",
        "(winW, winH) = (256,256)\n",
        "for idx in range(len(files)) :\n",
        "  file = files[idx]\n",
        "  if(file.endswith('.tif') or file.__contains__('mask')):\n",
        "    continue\n",
        "  img =cv2.resize(cv2.imread(file),(winW, winH))\n",
        "  pattern_img = cv2.resize(cv2.imread(file[:-4]+\".tif\"),(winW, winH))\n",
        "  prediction = siamese.predict([img, pattern_img])[0][0]"
      ],
      "metadata": {
        "id": "l2ZfQP_ceGYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model((256,256), 1)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "l6yVD_H3QtL5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train[:, 0],y_train,batch_size=4,epochs=5, validation_data=(x_test[:, 0], y_test))\n"
      ],
      "metadata": {
        "id": "jmScWJq2TnpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train[:, 0],y_train,batch_size=4,epochs=5, validation_data=(x_test[:, 0], y_test))\n"
      ],
      "metadata": {
        "id": "kqk7tMAsRF1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Part"
      ],
      "metadata": {
        "id": "9vFeA09_cCiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_metric(history, metric, title, has_valid=True):\n",
        "    \"\"\"Plots the given 'metric' from 'history'.\n",
        "\n",
        "    Arguments:\n",
        "        history: history attribute of History object returned from Model.fit.\n",
        "        metric: Metric to plot, a string value present as key in 'history'.\n",
        "        title: A string to be used as title of plot.\n",
        "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    plt.plot(history[metric])\n",
        "    if has_valid:\n",
        "        plt.plot(history[\"val_\" + metric])\n",
        "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot the accuracy\n",
        "plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
        "\n",
        "# Plot the constrastive loss\n",
        "plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
      ],
      "metadata": {
        "id": "yRA7j2zMGnRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = siamese.evaluate([x_test[:, 0], x_test[:, 1]], y_test)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAcrSkkCWBAV",
        "outputId": "efd49efe-4bdb-418e-8068-da92cf6bdafc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 20s 10s/step - loss: 0.2303 - accuracy: 0.9984\n",
            "test loss, test acc: [0.23026850819587708, 0.9983985424041748]\n"
          ]
        }
      ]
    }
  ]
}